
# ğŸ“˜ **MNIST Handwritten Digit Classification â€“ CNN From Scratch**

This project implements a **Convolutional Neural Network (CNN)** from scratch (without pre-trained models) to classify handwritten digits from the **MNIST dataset**.
The entire workflow includes data preprocessing, model building, training, evaluation, and visualization.

---

## ğŸ“‚ **Project Overview**

* **Dataset:** MNIST (70,000 grayscale images of digits 0â€“9)
* **Model:** Custom CNN built using **TensorFlow/Keras**
* **Task:** Multi-class classification
* **Input Size:** 28Ã—28Ã—1
* **Output:** Class probabilities for digits 0â€“9
* **Performance:** Achieved ~**98.9% test accuracy**

---

## ğŸ“Š **1. Dataset Preparation**

MNIST dataset is loaded using:

```python
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
```

### **Preprocessing Steps**

* Normalize pixel values â†’ **0 to 1**
* Reshape images to **(28, 28, 1)** for CNN input

---

## ğŸ§  **2. CNN Model Architecture**

A custom CNN was created using TensorFlow's Sequential API.

### **Model Layers**

1. **Conv2D (8 filters, 5Ã—5, ReLU)**
2. **MaxPooling2D (2Ã—2)**
3. **Conv2D (16 filters, 5Ã—5, ReLU)**
4. **MaxPooling2D (2Ã—2)**
5. **Flatten**
6. **Dense (128 units, ReLU)**
7. **Dropout (0.2)**
8. **Dense (10 units, Softmax)**

### **Model Summary**

* **Total parameters:** ~37,610
* **Trainable:** 100%

The architecture is optimized for small grayscale images.

---

## âš™ï¸ **3. Model Compilation**

The model uses:

| Component     | Choice                        |
| ------------- | ----------------------------- |
| Optimizer     | Adam (lr = 0.001)             |
| Loss Function | SparseCategoricalCrossentropy |
| Metrics       | Accuracy                      |

---

## ğŸ‹ï¸ **4. Training the Model**

* **Epochs:** 10
* **Batch Size:** 128
* **Validation Split:** 20%

Training produced:

* Increasing accuracy
* Decreasing loss
* Minimal overfitting

---

## ğŸ“ˆ **5. Training Curves**

Two graphs are plotted:

* **Training vs Validation Loss**
* **Training vs Validation Accuracy**

These help visualize learning performance over epochs.

---

## ğŸ§ª **6. Model Evaluation**

The model was evaluated on the test dataset:

```
Test accuracy: ~98.9%
Test loss: ~0.0379
```

Very high performance and generalization.

---

## ğŸ” **7. Predictions & Visualization**

The notebook displays a **5Ã—5 grid** of test images with:

* Predicted labels
* True labels

This helps visually inspect correctness and failure cases.

---

## ğŸ¯ **8. Key Features of This Project**

âœ” Fully custom CNN (no pre-trained models)
âœ” Clean training workflow
âœ” Visualization of images, training curves, and predictions
âœ” High accuracy on MNIST
âœ” Beginner-friendly deep learning project

---

## ğŸ“¦ **Technologies Used**

* TensorFlow / Keras
* NumPy
* Matplotlib
* Python 3.x
* Google Colab

---

## ğŸš€ **How to Run This Project**

1. Install dependencies:

```bash
pip install tensorflow numpy matplotlib
```

2. Run the notebook (`.ipynb`) or Python script.

3. The dataset will auto-download via Keras.

---

